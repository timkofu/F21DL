{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T15:58:39.841112Z",
     "start_time": "2019-11-04T15:58:39.836416Z"
    }
   },
   "outputs": [],
   "source": [
    "import set_sys_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T15:58:41.821459Z",
     "start_time": "2019-11-04T15:58:41.814668Z"
    }
   },
   "outputs": [],
   "source": [
    "from classy.controller.tasks import four"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T15:58:42.753897Z",
     "start_time": "2019-11-04T15:58:42.750756Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Classification: Performance of the Naive Bayes algorithm on the given data set] Run the Naive\n",
      "Bayes tool in Weka on the resulting version of train_gr_smpl. To be able to do this, you may need to\n",
      "apply several Weka “Filters”. Explain the reason for choosing and using these filters. Once you can run\n",
      "the algorithm, record, compare and analyse the classifier’s accuracy on different classes (as given by the\n",
      "Weka Summary and the confusion matrix).\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(four.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T15:58:45.483093Z",
     "start_time": "2019-11-04T15:58:44.726761Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load data from task 2\n",
    "from classy.model.data.read import Reader\n",
    "reader = Reader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T15:58:47.247410Z",
     "start_time": "2019-11-04T15:58:47.238632Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['task_2.hdf', 'task_1.hdf', 'dataframe_with_class_attribute.hdf']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader.list_data_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T15:58:48.455393Z",
     "start_time": "2019-11-04T15:58:48.054427Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = reader.load_data(\"dataframe_with_class_attribute\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T15:58:53.010260Z",
     "start_time": "2019-11-04T15:58:53.008051Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instruct pandas show everything we ask it\n",
    "# import pandas\n",
    "# pandas.set_option('display.max_columns', None)\n",
    "# pandas.set_option('display.max_rows', None)\n",
    "# Not as informative as I'd hoped. Need my own visual feature reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T15:58:57.487027Z",
     "start_time": "2019-11-04T15:58:57.470914Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2295</th>\n",
       "      <th>2296</th>\n",
       "      <th>2297</th>\n",
       "      <th>2298</th>\n",
       "      <th>2299</th>\n",
       "      <th>2300</th>\n",
       "      <th>2301</th>\n",
       "      <th>2302</th>\n",
       "      <th>2303</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>35</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>28</td>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26</td>\n",
       "      <td>25</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>36</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>42</td>\n",
       "      <td>40</td>\n",
       "      <td>37</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>33</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>37</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2305 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1   2   3   4   5   6   7   8   9  ...  2295  2296  2297  2298  2299  \\\n",
       "0  30  29  28  29  31  30  29  28  27  26  ...    32    35    38    39    39   \n",
       "1  31  31  33  32  31  30  29  28  28  28  ...    34    35    36    36    37   \n",
       "2  30  30  31  29  28  27  26  28  30  31  ...    35    37    37    38    39   \n",
       "3  26  25  24  24  24  27  28  29  29  30  ...    34    36    37    38    42   \n",
       "4  25  26  28  28  28  28  28  27  26  25  ...    31    33    37    38    37   \n",
       "\n",
       "   2300  2301  2302  2303  label  \n",
       "0    40    39    39    38      3  \n",
       "1    38    38    37    37      3  \n",
       "2    38    38    39    40      3  \n",
       "3    40    37    36    36      3  \n",
       "4    36    36    35    35      3  \n",
       "\n",
       "[5 rows x 2305 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T15:58:59.923558Z",
     "start_time": "2019-11-04T15:58:59.917907Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: 'speed_limit_60',\n",
       " 5: 'speed_limit_80',\n",
       " 6: 'speed_limit_80_lifted',\n",
       " 11: 'right_of_way_crossing',\n",
       " 12: 'right_of_way_general',\n",
       " 13: 'give_way',\n",
       " 14: 'stop',\n",
       " 32: 'no_speed_limit_general',\n",
       " 38: 'turn_right_down',\n",
       " 39: 'turn_left_down'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The classifier will output a label number, so let's get our mapping table mapped label_number to label_name\n",
    "label_mappings = {v:k for k,v in {\n",
    "    \"speed_limit_60\": 3,\n",
    "    \"speed_limit_80\": 5,\n",
    "    \"speed_limit_80_lifted\": 6,\n",
    "    \"right_of_way_crossing\": 11,\n",
    "    \"right_of_way_general\": 12,\n",
    "    \"give_way\": 13,\n",
    "    \"stop\": 14,\n",
    "    \"no_speed_limit_general\": 32,\n",
    "    \"turn_right_down\": 38,\n",
    "    \"turn_left_down\": 39,\n",
    "}.items()}\n",
    "label_mappings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Okay, now we're getting to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T15:59:04.485438Z",
     "start_time": "2019-11-04T15:59:03.965785Z"
    }
   },
   "outputs": [],
   "source": [
    "# First we want a stratified train test split.\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T15:59:07.944575Z",
     "start_time": "2019-11-04T15:59:07.941817Z"
    }
   },
   "outputs": [],
   "source": [
    "labels_numpy_array = dataset['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T15:59:08.937251Z",
     "start_time": "2019-11-04T15:59:08.933609Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12660,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_numpy_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T15:59:12.670565Z",
     "start_time": "2019-11-04T15:59:12.666936Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12660, 2305)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T15:59:14.719999Z",
     "start_time": "2019-11-04T15:59:14.716657Z"
    }
   },
   "outputs": [],
   "source": [
    "all_but_labels = dataset.iloc[:, :-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T15:59:16.791383Z",
     "start_time": "2019-11-04T15:59:16.788112Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: (12660, 2305) Labels: (12660,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Data:\", dataset.shape, \"Labels:\" ,labels_numpy_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the labels and instances and attributes in a numpy array as train_test split wants them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T15:59:20.423675Z",
     "start_time": "2019-11-04T15:59:20.044280Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now the actual train test split. Vamos!\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    all_but_labels, \n",
    "    labels_numpy_array,\n",
    "    # (70 30)% split\n",
    "    test_size=0.3,\n",
    "    # We want it stratified, labels equally distributed in the training and test datasets\n",
    "    stratify=labels_numpy_array\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're reader to run Naive Bayes.\n",
    "No dimensionality reduction via feature selection has been done on the data.\n",
    "Scikit-learn has 5 naive bayes types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T15:59:24.921215Z",
     "start_time": "2019-11-04T15:59:24.916113Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's start with Gaussian Naive Bayes, see what accuracy we get with that\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T15:59:28.327273Z",
     "start_time": "2019-11-04T15:59:28.324609Z"
    }
   },
   "outputs": [],
   "source": [
    "gnb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T15:59:29.184119Z",
     "start_time": "2019-11-04T15:59:29.180714Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (8862, 2304) y: (8862,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X:\", X_train.shape, \"y:\" ,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T15:59:31.379478Z",
     "start_time": "2019-11-04T15:59:31.005015Z"
    }
   },
   "outputs": [],
   "source": [
    "predictor = gnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T15:59:34.484108Z",
     "start_time": "2019-11-04T15:59:33.852462Z"
    }
   },
   "outputs": [],
   "source": [
    "predicted = predictor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T16:00:16.727859Z",
     "start_time": "2019-11-04T16:00:16.153792Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What's the accuracy?\n",
    "round(predictor.score(X_test, y_test), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the docs do say \"In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.\" But lets see if dimensionality reduction via feature selection helps with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T08:29:40.998603Z",
     "start_time": "2019-11-06T08:29:40.919682Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 60,  46, 225,   2,   0,  16,  47,  24,   3,   0],\n",
       "       [ 75, 135, 242,   3,   2,  28,  21,  29,   0,  23],\n",
       "       [  4,   3, 107,   0,   0,   0,   0,  12,   0,   0],\n",
       "       [ 15,  66,  57, 166,   4,  37,   1,  33,   3,  14],\n",
       "       [  8,  68, 166,  15, 134,  95,  26,  85,  18,  15],\n",
       "       [  9, 106, 113,   3,   3, 287,  11,  87,   7,  22],\n",
       "       [  3,  36,  14,   0,   4,  10, 144,   4,   3,  16],\n",
       "       [  7,   9,  11,   1,   1,   0,   2,  41,   0,   0],\n",
       "       [ 34,  72, 195,   4,  13, 115,  81,  18,  70,  19],\n",
       "       [  0,  13,  18,   0,   0,  16,  14,   4,   0,  25]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What does the confusion matrix look like?\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not good. Let's reduce the features, see if that improves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T16:00:32.414032Z",
     "start_time": "2019-11-04T16:00:32.401432Z"
    }
   },
   "source": [
    "We'll do the feature selection/reduction on the training data (X_train and y_train)\n",
    "\n",
    "Let's start with ANOVA (Analysis Of Variance). The test are univariate, and discard any feature that is significant only in combination with another.(ref_needed)\n",
    "\n",
    "scikit-learn has SelectKBest which takes a specified number of features to return, and SelectPercentile. We'll start with the latter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T09:12:40.191627Z",
     "start_time": "2019-11-06T09:12:40.188883Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectPercentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T09:13:24.509468Z",
     "start_time": "2019-11-06T09:13:24.505811Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8862, 2304)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many features do we have?\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T09:14:32.312698Z",
     "start_time": "2019-11-06T09:14:32.309988Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2304. Let's see what accuracy we gate with half\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T09:14:56.761286Z",
     "start_time": "2019-11-06T09:14:56.212328Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectPercentile(percentile=50, score_func=<function f_classif at 0x1a44cd5b90>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selekta.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T09:15:25.534949Z",
     "start_time": "2019-11-06T09:15:25.396019Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_selected = selekta.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T09:16:02.123113Z",
     "start_time": "2019-11-06T09:16:02.119632Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1152"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many features do we have now?\n",
    "X_train_selected.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T09:17:18.133598Z",
     "start_time": "2019-11-06T09:17:17.877144Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alright. Now lets train the model with that and see if the accuracy improves.\n",
    "gnb.fit(X_train_selected, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T09:18:29.340301Z",
     "start_time": "2019-11-06T09:18:29.187421Z"
    }
   },
   "outputs": [],
   "source": [
    "# We need to select the X_test too\n",
    "X_test_selected = selekta.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T09:19:58.427109Z",
     "start_time": "2019-11-06T09:19:58.117933Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3665086887835703"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And see how the classifier scores on that\n",
    "gnb.score(X_test_selected, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "36% accuracy now, but we can do better.\n",
    "\n",
    "What about with 20% of the features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T10:51:31.966909Z",
     "start_time": "2019-11-06T10:51:31.440040Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39046866771985256"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selekta = SelectPercentile(percentile=20)\n",
    "selekta.fit(X_train, y_train)\n",
    "X_train_selected = selekta.transform(X_train)\n",
    "gnb.fit(X_train_selected, y_train)\n",
    "X_test_selected = selekta.transform(X_test)\n",
    "gnb.score(X_test_selected, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T10:58:47.608128Z",
     "start_time": "2019-11-06T10:58:47.212545Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36334913112164297"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 39% much better! What about 10% ??\n",
    "selekta = SelectPercentile(percentile=10)\n",
    "selekta.fit(X_train, y_train)\n",
    "X_train_selected = selekta.transform(X_train)\n",
    "gnb.fit(X_train_selected, y_train)\n",
    "X_test_selected = selekta.transform(X_test)\n",
    "gnb.score(X_test_selected, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T10:56:16.555646Z",
     "start_time": "2019-11-06T10:56:16.480845Z"
    }
   },
   "source": [
    "Okay, so 20% is the point of diminishing returns for this dataset.\n",
    "\n",
    "But what if we use a model to work out which features are best? scikit-learn enables us to use a random forest classifier to do just that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T11:05:01.645237Z",
     "start_time": "2019-11-06T11:05:01.642390Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T11:14:50.780283Z",
     "start_time": "2019-11-06T11:14:50.761331Z"
    }
   },
   "outputs": [],
   "source": [
    "selekta = SelectFromModel(\n",
    "    RandomForestClassifier(\n",
    "        n_estimators=100, # Chose this purely randomly\n",
    "        random_state=42, # Deterministic tree generation\n",
    "        n_jobs=4, # I have 4 cores\n",
    "    ),\n",
    "    threshold=\"median\", # >= the median of feature importances, so same as for 50% with SelectPercentile\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T11:12:36.808307Z",
     "start_time": "2019-11-06T11:12:31.207369Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37519747235387046"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selekta.fit(X_train, y_train)\n",
    "X_train_selected = selekta.transform(X_train)\n",
    "gnb.fit(X_train_selected, y_train)\n",
    "X_test_selected = selekta.transform(X_test)\n",
    "gnb.score(X_test_selected, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T11:28:25.449717Z",
     "start_time": "2019-11-06T11:28:25.438755Z"
    }
   },
   "outputs": [],
   "source": [
    "# 37%, now we get the best 20%\n",
    "selekta = SelectFromModel(\n",
    "    RandomForestClassifier(\n",
    "        n_estimators=100, # Chose this purely randomly\n",
    "        random_state=42, # Deterministic tree generation\n",
    "        n_jobs=4, # I have 4 cores\n",
    "    ),\n",
    "    threshold=\"0.80*mean\", # Best 20%\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T11:28:32.394550Z",
     "start_time": "2019-11-06T11:28:27.526307Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8862, 593)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selekta.fit(X_train, y_train)\n",
    "X_train_selected = selekta.transform(X_train)\n",
    "X_train_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T11:21:35.203972Z",
     "start_time": "2019-11-06T11:21:35.199983Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "460.6"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(20*2303)/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T11:33:13.637259Z",
     "start_time": "2019-11-06T11:33:13.218918Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41047919957872564"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb.fit(X_train_selected, y_train)\n",
    "X_test_selected = selekta.transform(X_test)\n",
    "gnb.score(X_test_selected, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T11:33:48.444781Z",
     "start_time": "2019-11-06T11:33:48.441104Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3798, 2304)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T11:34:34.058650Z",
     "start_time": "2019-11-06T11:34:34.054872Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.73784722222222"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(593*100)/2304"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So 25% of the features produce 41% accuracy ... with GaussianNB, maybe another NB will do better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T11:51:59.539909Z",
     "start_time": "2019-11-06T11:51:59.537367Z"
    }
   },
   "outputs": [],
   "source": [
    "# Lets see how complement naive bayes does\n",
    "from sklearn.naive_bayes import ComplementNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T11:52:05.037953Z",
     "start_time": "2019-11-06T11:52:05.035285Z"
    }
   },
   "outputs": [],
   "source": [
    "cnb = ComplementNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T11:53:20.249833Z",
     "start_time": "2019-11-06T11:53:20.080544Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7132701421800948"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Then train it as the gnb\n",
    "cnb.fit(X_train_selected, y_train)\n",
    "X_test_selected = selekta.transform(X_test)\n",
    "cnb.score(X_test_selected, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jesus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bernouli Naive Bayes is for binary data. So really CNB is the classifier for this data. I need to work out why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T11:58:05.396805Z",
     "start_time": "2019-11-06T11:58:05.212849Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4636650868878357"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How does it perform with the no-dimentionally reduced data?\n",
    "cnb.fit(X_train, y_train)\n",
    "cnb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T11:59:51.834166Z",
     "start_time": "2019-11-06T11:59:46.780176Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6045286993154292"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alright. So the dimensionality reduction makes it do better (as expected). \n",
    "# But how about with 50% of the features selected by the tree?\n",
    "selekta = SelectFromModel(\n",
    "    RandomForestClassifier(\n",
    "        n_estimators=100, # Chose this purely randomly\n",
    "        random_state=42, # Deterministic tree generation\n",
    "        n_jobs=4, # I have 4 cores\n",
    "    ),\n",
    "    threshold=\"median\", # >= the median of feature importances, so same as for 50% with SelectPercentile\n",
    ")\n",
    "selekta.fit(X_train, y_train)\n",
    "X_train_selected = selekta.transform(X_train)\n",
    "cnb.fit(X_train_selected, y_train)\n",
    "X_test_selected = selekta.transform(X_test)\n",
    "cnb.score(X_test_selected, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T11:20:40.229845Z",
     "start_time": "2019-11-06T11:20:40.226273Z"
    }
   },
   "source": [
    "Very nice. How about 20% of of the SelectPercentile ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T12:02:47.106193Z",
     "start_time": "2019-11-06T12:02:47.103583Z"
    }
   },
   "outputs": [],
   "source": [
    "selekta = SelectPercentile(percentile=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T12:02:49.226971Z",
     "start_time": "2019-11-06T12:02:48.831398Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6579778830963665"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selekta.fit(X_train, y_train)\n",
    "X_train_selected = selekta.transform(X_train)\n",
    "cnb.fit(X_train_selected, y_train)\n",
    "X_test_selected = selekta.transform(X_test)\n",
    "cnb.score(X_test_selected, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are conclusive, and here they are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T12:12:40.089648Z",
     "start_time": "2019-11-06T12:12:35.279763Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7132701421800948"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selekta = SelectFromModel(\n",
    "    RandomForestClassifier(\n",
    "        n_estimators=100, # Chose this purely randomly\n",
    "        random_state=42, # Deterministic tree generation\n",
    "        n_jobs=4, # I have 4 cores\n",
    "    ),\n",
    "    threshold=\"0.8*mean\", # Best 25% based on feature importances\n",
    ")\n",
    "selekta.fit(X_train, y_train)\n",
    "X_train_selected = selekta.transform(X_train)\n",
    "cnb.fit(X_train_selected, y_train)\n",
    "X_test_selected = selekta.transform(X_test)\n",
    "cnb.score(X_test_selected, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model based feature selection with RandomForest as the model, produces features that produce the best classification using a Complement Naive Bayes classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T12:28:21.936747Z",
     "start_time": "2019-11-06T12:28:21.918339Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 16, 173,   0,  18,  89, 114,   1,   0,  12,   0],\n",
       "       [  0, 316,   0,  25,  79, 122,   0,   0,  16,   0],\n",
       "       [  0,   0,   0,   3, 123,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0, 360,  35,   0,   0,   0,   1,   0],\n",
       "       [  0,  22,   0,  21, 571,  14,   0,   0,   2,   0],\n",
       "       [  0,   0,   0,  20,  12, 615,   1,   0,   0,   0],\n",
       "       [  0,   0,   0,   2,   3,   1, 225,   0,   3,   0],\n",
       "       [  0,   3,   0,   1,  66,   1,   0,   0,   1,   0],\n",
       "       [  0,   0,   0,   0,  28,  17,   0,   0, 576,   0],\n",
       "       [  0,   0,   0,   7,  10,  43,   0,   0,   0,  30]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How does the confusion matrix look like?\n",
    "predicted = cnb.predict(X_test_selected)\n",
    "confusion_matrix(y_test, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MUCH better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T12:31:03.882001Z",
     "start_time": "2019-11-06T12:31:03.879781Z"
    }
   },
   "outputs": [],
   "source": [
    "# And a more detailed report\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T12:32:04.999247Z",
     "start_time": "2019-11-06T12:32:04.988822Z"
    }
   },
   "outputs": [],
   "source": [
    "report = classification_report(\n",
    "    y_test, predicted\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T12:32:09.230761Z",
     "start_time": "2019-11-06T12:32:09.227823Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       1.00      0.04      0.07       423\n",
      "           5       0.61      0.57      0.59       558\n",
      "           6       0.00      0.00      0.00       126\n",
      "          11       0.79      0.91      0.84       396\n",
      "          12       0.56      0.91      0.69       630\n",
      "          13       0.66      0.95      0.78       648\n",
      "          14       0.99      0.96      0.98       234\n",
      "          32       0.00      0.00      0.00        72\n",
      "          38       0.94      0.93      0.94       621\n",
      "          39       1.00      0.33      0.50        90\n",
      "\n",
      "    accuracy                           0.71      3798\n",
      "   macro avg       0.66      0.56      0.54      3798\n",
      "weighted avg       0.73      0.71      0.66      3798\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-cv2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
